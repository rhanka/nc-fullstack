#!/usr/bin/env python3
"""extract_jsons.py
--------------------------------------------------
Extrait la derni√®re colonne (JSON) d'un CSV.gz tabul√© et
√©crit un fichier .json par ligne, nomm√© d'apr√®s l'avant-derni√®re colonne.

Format pr√©vu (export Dataiku) :
col1 <TAB> ‚Ä¶ <TAB> file_id <TAB> "{"000": ‚Ä¶ }"\n
- Le fichier est encod√© UTF-8 et compress√© gzip.
- La premi√®re ligne est un header √† ignorer.
"""
import csv
import gzip
import json
import pathlib
import sys
from typing import TextIO, Any

SRC_PATH = pathlib.Path(__file__).parent.parent / "api/data/a220-non-conformities/managed_dataset/NC_types_random_500_final_structured.csv.gz"
DST_DIR = pathlib.Path(__file__).parent.parent / "api/data/a220-non-conformities/json"


def open_csv(path: pathlib.Path) -> TextIO:
    """Ouvre le fichier gzip en texte UTF-8 et retourne un it√©rateur de lignes."""
    try:
        return gzip.open(path, mode="rt", encoding="utf-8", newline="")
    except FileNotFoundError:
        print(f"‚ùå Fichier source introuvable : {path}", file=sys.stderr)
        sys.exit(1)


def parse_double_json(field: str) -> Any:
    """D√©codage robuste d'un champ JSON doublement encod√©.

    1) Le champ est d'abord une *cha√Æne JSON* encadr√©e de guillemets dans le CSV
       (tous les \" internes sont √©chapp√©s).
    2) On applique json.loads une premi√®re fois : on obtient soit un dict
       directement, soit une *cha√Æne* JSON propre (cas Dataiku).
    3) Si c'est encore une cha√Æne, on applique json.loads une seconde fois.
    """

    obj = json.loads(field)
    return obj


def main() -> None:
    DST_DIR.mkdir(parents=True, exist_ok=True)
    print(f"üìÇ Dossier de sortie : {DST_DIR}")

    with open_csv(SRC_PATH) as fh:
        reader = csv.reader(
            fh,
            delimiter="\t",
            quotechar='"',
            escapechar='\\',   # Dataiku √©chappe les guillemets avec \"
            doublequote=False,  # donc pas de "" pour un guillemet interne
            quoting=csv.QUOTE_MINIMAL,
        )

        # Sauter l'en-t√™te si pr√©sent
        header = next(reader, None)
        if header is None:
            print("‚ö†Ô∏è  Le fichier est vide.")
            return

        err_count = 0
        for line_no, row in enumerate(reader, start=2):  # +1 pour header, +1 pour 1-index√©
            if len(row) < 2:
                print(f"‚è≠Ô∏è  Ligne {line_no}: moins de deux colonnes, ignor√©e.")
                continue

            file_id = row[-2].strip()
            json_raw = row[-1]

            if not file_id:
                print(f"‚è≠Ô∏è  Ligne {line_no}: identifiant vide, ignor√©e.")
                continue

            try:
                data = json.loads(json_raw)
            except json.JSONDecodeError as e:
                err_count += 1
                print(f"‚õî Ligne {line_no} (ID={file_id}) : JSON invalide ‚Üí {e.msg}")
                continue

            out_path = DST_DIR / f"{file_id}.json"
            with out_path.open("w", encoding="utf-8") as out_f:
                json.dump(data, out_f, ensure_ascii=False, indent=2)

        print("‚úÖ Extraction termin√©e.")
        if err_count:
            print(f"‚ö†Ô∏è  {err_count} ligne(s) ignor√©e(s) pour JSON invalide.")


if __name__ == "__main__":
    main() 